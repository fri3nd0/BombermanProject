{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bbe88005-be9f-46e7-8600-019ed0bc7dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "sys.path.append(r\"../..\")\n",
    "\n",
    "\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from callbacks import state_to_features, ACTION_MAP, ACTION_MAP_INV\n",
    "from networks import AgentNet\n",
    "\n",
    "from events import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "198f4ee7-8582-4580-8cb9-fbccd2d77655",
   "metadata": {},
   "outputs": [],
   "source": [
    "EVENT_HORIZON = {\n",
    "    MOVED_LEFT: 1,\n",
    "    MOVED_RIGHT: 1,\n",
    "    MOVED_UP: 1,\n",
    "    MOVED_DOWN: 1,\n",
    "    WAITED: 2,\n",
    "    INVALID_ACTION: 1,\n",
    "    BOMB_DROPPED: 2,\n",
    "    BOMB_EXPLODED: 2,\n",
    "    CRATE_DESTROYED: 8,\n",
    "    COIN_FOUND: 3,\n",
    "    COIN_COLLECTED: 5,\n",
    "    KILLED_OPPONENT: 8,\n",
    "    KILLED_SELF: 3,\n",
    "    GOT_KILLED: 3,\n",
    "    OPPONENT_ELIMINATED: 0,\n",
    "    SURVIVED_ROUND: 8\n",
    "}\n",
    "\"\"\"\n",
    "REWARDS = {\n",
    "    MOVED_LEFT: 1,\n",
    "    MOVED_RIGHT: 1,\n",
    "    MOVED_UP: 1,\n",
    "    MOVED_DOWN: 1,\n",
    "    WAITED: 0,\n",
    "    INVALID_ACTION: -5,\n",
    "    BOMB_DROPPED: 1,\n",
    "    BOMB_EXPLODED: 0,\n",
    "    CRATE_DESTROYED: 4,\n",
    "    COIN_FOUND: 0,\n",
    "    COIN_COLLECTED: 5,\n",
    "    KILLED_OPPONENT: 5,\n",
    "    KILLED_SELF: -8,\n",
    "    GOT_KILLED: -8,\n",
    "    OPPONENT_ELIMINATED: 0,\n",
    "    SURVIVED_ROUND: 0\n",
    "}\n",
    "\"\"\"\n",
    "REWARDS = {\n",
    "    MOVED_LEFT: 100,\n",
    "    MOVED_RIGHT: 100,\n",
    "    MOVED_UP: 100,\n",
    "    MOVED_DOWN: 100,\n",
    "    WAITED: -100,\n",
    "    INVALID_ACTION: -10,\n",
    "    BOMB_DROPPED: 0,\n",
    "    BOMB_EXPLODED: 0,\n",
    "    CRATE_DESTROYED: 0,\n",
    "    COIN_FOUND: 0,\n",
    "    COIN_COLLECTED: 0,\n",
    "    KILLED_OPPONENT: 0,\n",
    "    KILLED_SELF: 0,\n",
    "    GOT_KILLED: 0,\n",
    "    OPPONENT_ELIMINATED: 0,\n",
    "    SURVIVED_ROUND: 0\n",
    "}\n",
    "\n",
    "# REWARDS = {k: v + 10 for k, v in REWARDS.items()}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d043e5d7-68f4-494b-9e02-6aac7b9d7022",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b315449-5fd7-449a-95fd-f0ad35deebbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify directory with training data\n",
    "data_path = \"../data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd3d386",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.random.normal())\n",
    "ns = np.zeros(1000)\n",
    "for i in range(1000):\n",
    "    ns[i] = np.random.normal()\n",
    "\n",
    "plt.hist(ns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4f6ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    " if i > 12:\n",
    "                    if data['events'][i-4] == data['events'][i] and data['events'][i-4] == data['events'][i-8]:\n",
    "                        if data['events'][i-3] == data['events'][i-7]:\n",
    "                            if data['events'][i] in [\"MOVED_LEFT\", \"MOVED_RIGHT\", \"MOVED_UP\", \"MOVED_DOWN\"]:\n",
    "                                if data['events'][i-3] in [\"MOVED_LEFT\", \"MOVED_RIGHT\", \"MOVED_UP\", \"MOVED_DOWN\"]:\n",
    "                                    if data['events'][i-8] == data['events'][i-12]:\n",
    "                                \n",
    "                                        rewards[0] -= 1/50*(REWARDS[\"MOVED_LEFT\"]+REWARDS[\"MOVED_RIGHT\"]+REWARDS[\"MOVED_UP\"]+REWARDS[\"MOVED_DOWN\"])\n",
    "                        \n",
    "                if i>10:\n",
    "                    if data['events'][i-2] == data['events'][i] and data['events'][i-4] == data['events'][i-2]:\n",
    "                        if data['events'][i-4] == data['events'][i-6] and data['events'][i-8] == data['events'][i-6]:\n",
    "                            if data['events'][i-3] == data['events'][i-5]:\n",
    "                                if data['events'][i-3] in [\"MOVED_LEFT\", \"MOVED_RIGHT\", \"MOVED_UP\", \"MOVED_DOWN\"]:\n",
    "                                    if data['events'][i-8] == data['events'][i-10]:\n",
    "                                        if data['events'][i] in [\"MOVED_LEFT\", \"MOVED_RIGHT\", \"MOVED_UP\", \"MOVED_DOWN\"]:\n",
    "                                            rewards[0] -= 1/50*(REWARDS[\"MOVED_LEFT\"]+REWARDS[\"MOVED_RIGHT\"]+REWARDS[\"MOVED_UP\"]+REWARDS[\"MOVED_DOWN\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7369f91a-b21e-407c-bced-63e441be02a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class BombermanDataset(Dataset):\n",
    "    def __init__(self, states_dir, max_game_step=200, min_reward=1):\n",
    "        self.features = []\n",
    "        self.actions = []\n",
    "        self.cum_rewards = []\n",
    "        self.total_number = 0\n",
    "        for states_file in os.listdir(states_dir):\n",
    "\n",
    "            if not states_file.endswith('.pickle'):\n",
    "                continue\n",
    "            with open(os.path.join(states_dir, states_file), \"rb\") as f:\n",
    "                data = pickle.load(f)\n",
    "            self.total_number += len(data['game_state'])\n",
    "            last_round = -1\n",
    "            running_horizons = []\n",
    "            running_rewards = []\n",
    "            for i in range(len(data['game_state'])-1,-1,-1):\n",
    "                game_state = data['game_state'][i]               \n",
    "\n",
    "                    \n",
    "                if last_round != game_state['round']:\n",
    "                    last_round = game_state['round']\n",
    "                    running_horizons = []\n",
    "                    running_rewards = []\n",
    "                if game_state['step'] > max_game_step:\n",
    "                    continue\n",
    "                    \n",
    "                # determine if action should be included in training set\n",
    "                \n",
    "                horizons = [EVENT_HORIZON[e] for e in data['events'][i]]\n",
    "                rewards = [REWARDS[e] for e in data['events'][i]]\n",
    "                cr = np.where(data['events'] == \"CRATE_DESTROYED\")\n",
    "                #print(cr)\n",
    "                #rewards[np.array(cr[-1:], dtype = \"int\")] == 0\n",
    "                #for j in cr[1:]:\n",
    "                #    rewards[j] = 0             \n",
    "\n",
    "                running_rewards = [r for j,r in enumerate(running_rewards) if running_horizons[j]>1]\n",
    "                running_horizons = [h-1 for h in running_horizons if h > 1]\n",
    "                running_rewards.extend(rewards)\n",
    "                running_horizons.extend(horizons)\n",
    "                #if \"INVALID_ACTION\" in data['events'][i]:\n",
    "                #    continue   \n",
    "                self.cum_rewards.append(np.sum(running_rewards))\n",
    "\n",
    "                last_action = None if game_state['step'] == 1 else data['action'][i-1]\n",
    "                #print(\"LAST ACTION:\")\n",
    "                #print(last_action)\n",
    "                \n",
    "                channels, coin_map, features, act_map = state_to_features(game_state, last_action=last_action)\n",
    "                action = ACTION_MAP[act_map[data['action'][i]]]\n",
    "                self.features.append((\n",
    "                    torch.tensor(channels[np.newaxis], dtype=torch.float),\n",
    "                    torch.tensor(coin_map[np.newaxis], dtype=torch.float),\n",
    "                    torch.tensor(features, dtype=torch.float)\n",
    "                ))\n",
    "                self.actions.append(action)\n",
    "                \n",
    "                    \n",
    "        self.cum_rewards = torch.tensor(self.cum_rewards, dtype=torch.float)\n",
    "        self.n = np.array([np.sum([t == i for t in self.actions]) for i in range(6)])\n",
    "        self.weights = np.array([1/self.n[t] for t in self.actions])\n",
    "        self.proportion_selected = len(self.actions)/self.total_number\n",
    "        print(f\"Loaded {len(self.actions)} actions.\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.features[idx], self.actions[idx], self.cum_rewards[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ea29de",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.system(\"rm -rf ../data\")\n",
    "os.system(\"cd ../..; python main.py play --no-gui --agents rule_based_agent rule_based_agent rule_based_agent rule_based_agent --train 4 --n-rounds 5 --scenario loot-crate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c139c1dd-3977-48c1-8ac7-0f2aaa79b629",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = BombermanDataset(data_path)\n",
    "\n",
    "N = len(trainset)\n",
    "print(f\"{N} actions in the training set:\")\n",
    "for i in range(6):\n",
    "    n = np.sum([t == i for t in trainset.actions])\n",
    "    print(f\"{ACTION_MAP_INV[i]}: {n/N*100:.2f}% ({n})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f04077-fc6e-490a-aab2-4e73ce8a4e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e06fd2-2c30-4d16-8541-3e5b375dac0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = AgentNet()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e264d2-5f69-4bc0-b1a3-c290f9b633df",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "os.makedirs(\"models\", exist_ok=True)\n",
    "for epoch in range(5):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, batch in enumerate(trainloader, 0):\n",
    "        print(i, end=\"\\r\")\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        (channels, features), actions, rewards = batch\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(channels, features)\n",
    "        # loss = criterion(outputs, labels)\n",
    "        log_logits = F.log_softmax(outputs, dim=-1)\n",
    "        log_probs = log_logits.gather(1, actions[:,np.newaxis])\n",
    "        \n",
    "        loss = torch.mean(-log_probs * rewards)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 200 == 199:    # print every 2000 mini-batches\n",
    "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n",
    "            torch.save(net.state_dict(), 'models/model_weights.pth')\n",
    "            running_loss = 0.0\n",
    "\n",
    "torch.save(net.state_dict(), 'models/model_weights.pth')\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e7bdce-f727-442f-b256-45c51e4d3100",
   "metadata": {},
   "outputs": [],
   "source": [
    "a.gather(1, torch.tensor([0,1,0])[:,np.newaxis])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "083d1a72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "21642fa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n"
     ]
    }
   ],
   "source": [
    "expnet = AgentNet()\n",
    "expnet.load_state_dict(torch.load(\"models/model_weights.pth\"))\n",
    "#(channels, features), actions, rewards = enumerate(trainloader,0)\n",
    "#print(expnet.cnn(trainloader).size())\n",
    "for i, batch in enumerate(trainloader,0):\n",
    "    if i%100==0:\n",
    "        (channels, features), actions, rewards = batch    \n",
    "        print(expnet.cnn(channels).size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "944b4018-e9a4-45ce-825b-41f22809126e",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "data_path = f\"../data/\"\n",
    "weight_path = \"models/model_weights_pretrained.pth\"\n",
    "num_epoch_per_run = 1\n",
    "\n",
    "# optimizer = optim.SGD(net.parameters(), momentum=0.9, lr=0.001)\n",
    "net = AgentNet()\n",
    "#net.load_state_dict(torch.load(weight_path))\n",
    "torch.save(net.state_dict(), weight_path)\n",
    "optimizer = optim.AdamW(net.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7b090f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.AdamW(net.parameters(), lr=0.001)\n",
    "batch_size = 128\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a87534bb-9e02-4b62-8053-194d219d0ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "EVENT_HORIZON = {\n",
    "    MOVED_LEFT: 1,\n",
    "    MOVED_RIGHT: 1,\n",
    "    MOVED_UP: 1,\n",
    "    MOVED_DOWN: 1,\n",
    "    WAITED: 1,\n",
    "    INVALID_ACTION: 1,\n",
    "    BOMB_DROPPED: 1,\n",
    "    BOMB_EXPLODED: 1,\n",
    "    CRATE_DESTROYED: 6,\n",
    "    COIN_FOUND: 1,\n",
    "    COIN_COLLECTED: 5,\n",
    "    KILLED_OPPONENT: 6,\n",
    "    KILLED_SELF: 5,\n",
    "    GOT_KILLED: 5,\n",
    "    OPPONENT_ELIMINATED: 4,\n",
    "    SURVIVED_ROUND: 100\n",
    "}\n",
    "\n",
    "\n",
    "REWARDS = {\n",
    "    MOVED_LEFT: 5, #1\n",
    "    MOVED_RIGHT: 5, #1\n",
    "    MOVED_UP: 5,   #1\n",
    "    MOVED_DOWN: 5,  #1\n",
    "    WAITED: 5,  #1\n",
    "    INVALID_ACTION: -120, #-7\n",
    "    BOMB_DROPPED: 5,  #1\n",
    "    BOMB_EXPLODED: 0,\n",
    "    CRATE_DESTROYED: 120,\n",
    "    COIN_FOUND: 0,\n",
    "    COIN_COLLECTED: 120,\n",
    "    KILLED_OPPONENT: 60,\n",
    "    KILLED_SELF: -120, #-12\n",
    "    GOT_KILLED: -120,\n",
    "    OPPONENT_ELIMINATED: 5,\n",
    "    SURVIVED_ROUND: 200 #20\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2f25651b-d431-4812-be1b-1419aeccbf0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:40<00:00,  1.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 299053 actions.\n",
      "299053 actions in the training set:\n",
      "UP: 19.54% (58446)\n",
      "DOWN: 25.46% (76125)\n",
      "LEFT: 19.64% (58742)\n",
      "RIGHT: 24.97% (74684)\n",
      "BOMB: 8.82% (26380)\n",
      "WAIT: 1.56% (4676)\n",
      "[1, 1,   200] loss: 136.369\n",
      "[1, 1,   400] loss: 102.849\n",
      "[1, 1] loss: 88.911\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:43<00:00,  1.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 309536 actions.\n",
      "309536 actions in the training set:\n",
      "UP: 19.33% (59841)\n",
      "DOWN: 25.42% (78675)\n",
      "LEFT: 19.58% (60592)\n",
      "RIGHT: 25.32% (78367)\n",
      "BOMB: 8.68% (26883)\n",
      "WAIT: 1.67% (5178)\n",
      "[2, 1,   200] loss: 117.717\n",
      "[2, 1,   400] loss: 97.284\n",
      "[2, 1] loss: 85.625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:35<00:00,  1.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 287701 actions.\n",
      "287701 actions in the training set:\n",
      "UP: 19.75% (56822)\n",
      "DOWN: 25.49% (73332)\n",
      "LEFT: 19.28% (55475)\n",
      "RIGHT: 25.13% (72305)\n",
      "BOMB: 8.55% (24608)\n",
      "WAIT: 1.79% (5159)\n",
      "[3, 1,   200] loss: 103.858\n",
      "[3, 1,   400] loss: 77.349\n",
      "[3, 1] loss: 66.042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:38<00:00,  1.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 284629 actions.\n",
      "284629 actions in the training set:\n",
      "UP: 19.77% (56273)\n",
      "DOWN: 25.33% (72091)\n",
      "LEFT: 19.53% (55575)\n",
      "RIGHT: 25.06% (71338)\n",
      "BOMB: 8.62% (24544)\n",
      "WAIT: 1.69% (4808)\n",
      "[4, 1,   200] loss: 100.633\n",
      "[4, 1,   400] loss: 76.973\n",
      "[4, 1] loss: 70.120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [43:35<00:00, 87.18s/it]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 298836 actions.\n",
      "298836 actions in the training set:\n",
      "UP: 19.47% (58169)\n",
      "DOWN: 25.52% (76250)\n",
      "LEFT: 19.31% (57709)\n",
      "RIGHT: 25.25% (75467)\n",
      "BOMB: 8.78% (26233)\n",
      "WAIT: 1.68% (5008)\n",
      "[5, 1,   200] loss: 95.842\n",
      "[5, 1,   400] loss: 72.348\n",
      "[5, 1] loss: 60.415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:36<00:00,  1.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 292287 actions.\n",
      "292287 actions in the training set:\n",
      "UP: 19.08% (55757)\n",
      "DOWN: 24.97% (72980)\n",
      "LEFT: 19.83% (57970)\n",
      "RIGHT: 25.69% (75074)\n",
      "BOMB: 8.76% (25594)\n",
      "WAIT: 1.68% (4912)\n",
      "[6, 1,   200] loss: 93.912\n",
      "[6, 1,   400] loss: 68.969\n",
      "[6, 1] loss: 59.282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:41<00:00,  1.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 287635 actions.\n",
      "287635 actions in the training set:\n",
      "UP: 19.46% (55981)\n",
      "DOWN: 25.56% (73514)\n",
      "LEFT: 19.37% (55707)\n",
      "RIGHT: 25.20% (72488)\n",
      "BOMB: 8.70% (25031)\n",
      "WAIT: 1.71% (4914)\n",
      "[7, 1,   200] loss: 92.635\n",
      "[7, 1,   400] loss: 70.993\n",
      "[7, 1] loss: 62.342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:42<00:00,  1.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "358\n",
      "410\n",
      "336\n",
      "337\n",
      "Loaded 310690 actions.\n",
      "310690 actions in the training set:\n",
      "UP: 19.72% (61272)\n",
      "DOWN: 25.26% (78476)\n",
      "LEFT: 19.58% (60847)\n",
      "RIGHT: 24.92% (77438)\n",
      "BOMB: 8.65% (26871)\n",
      "WAIT: 1.86% (5786)\n",
      "[8, 1,   200] loss: 101.924\n",
      "[8, 1,   400] loss: 75.507\n",
      "[8, 1] loss: 61.154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [01:00<00:00,  2.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rule_based_agent_0    325\n",
      "rule_based_agent_1    371\n",
      "rule_based_agent_2    366\n",
      "rule_based_agent_3    386\n",
      "Loaded 275315 actions.\n",
      "275315 actions in the training set:\n",
      "UP: 19.65% (54096)\n",
      "DOWN: 25.40% (69936)\n",
      "LEFT: 19.14% (52691)\n",
      "RIGHT: 25.16% (69267)\n",
      "BOMB: 8.73% (24047)\n",
      "WAIT: 1.92% (5278)\n",
      "[9, 1,   200] loss: 92.315\n",
      "[9, 1,   400] loss: 63.327\n",
      "[9, 1] loss: 53.332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [01:05<00:00,  2.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rule_based_agent_0    347\n",
      "rule_based_agent_1    373\n",
      "rule_based_agent_2    372\n",
      "rule_based_agent_3    356\n",
      "Loaded 286406 actions.\n",
      "286406 actions in the training set:\n",
      "UP: 19.31% (55309)\n",
      "DOWN: 25.24% (72279)\n",
      "LEFT: 19.51% (55891)\n",
      "RIGHT: 25.72% (73663)\n",
      "BOMB: 8.51% (24373)\n",
      "WAIT: 1.71% (4891)\n",
      "[10, 1,   200] loss: 90.488\n",
      "[10, 1,   400] loss: 60.291\n",
      "[10, 1] loss: 52.168\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for run in range(10):\n",
    "    # os.system(\"rm -rf ../rule_based_agent/data\")\n",
    "    os.system(\"rm -rf ../data\")\n",
    "    os.system(\"cd ../..; python main.py play --no-gui --agents rule_based_agent rule_based_agent rule_based_agent rule_based_agent --train 4 --n-rounds 30 --scenario loot-crate\")\n",
    "\n",
    "    trainset = BombermanDataset(data_path)\n",
    "    N = len(trainset)\n",
    "    print(f\"{N} actions in the training set:\")\n",
    "    for i in range(6):\n",
    "        n = np.sum([t == i for t in trainset.actions])\n",
    "        print(f\"{ACTION_MAP_INV[i]}: {n/N*100:.2f}% ({n})\")\n",
    "    # sampler = BatchSampler(WeightedRandomSampler(trainset.weights, len(trainset), replacement=True,), batch_size, False)\n",
    "    # trainloader = torch.utils.data.DataLoader(trainset, batch_sampler=sampler)\n",
    "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    for epoch in range(num_epoch_per_run):\n",
    "        running_loss = 0.0\n",
    "        running = 0\n",
    "        for i, batch in enumerate(trainloader, 0):\n",
    "        # for i, batch in enumerate(sampler, 0):\n",
    "            print(i, end=\"\\r\")\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            (channels, coin_map, features), actions, rewards = batch\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "    \n",
    "            # forward + backward + optimize\n",
    "            outputs = net(channels, coin_map, features)\n",
    "            # loss = criterion(outputs, labels)\n",
    "            log_logits = F.log_softmax(outputs, dim=-1)\n",
    "            log_probs = log_logits.gather(1, actions[:,np.newaxis])\n",
    "            \n",
    "            loss = torch.mean(-log_probs * rewards)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "            running += 1\n",
    "            if i % 200 == 199:    # print every 2000 mini-batches\n",
    "                print(f'[{run + 1}, {epoch + 1}, {i + 1:5d}] loss: {running_loss / running:.3f}')\n",
    "                torch.save(net.state_dict(), weight_path)\n",
    "                running_loss = 0.0\n",
    "                running = 0\n",
    "                #print(log_probs)\n",
    "                #print(rewards)\n",
    "            if i*batch_size/N > 0.2:\n",
    "                break\n",
    "        if running > 0:\n",
    "            print(f'[{run + 1}, {epoch + 1}] loss: {running_loss / running:.3f}')\n",
    "    torch.save(net.state_dict(), weight_path)\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "25463da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(), \"models/model_weights.pth\")\n",
    "\n",
    "\n",
    "#weight_path_ref = \"models/model_weights_pretrained_ref.pth\"\n",
    "#torch.save(net.state_dict(),weight_path_ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "0136c04c-7b35-43b8-a5e1-9a83f30dc43c",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "data_path = f\"../data/\"\n",
    "weight_path = \"models/model_weights.pth\"\n",
    "pretrained_weight_path = \"models/model_weights_pretrained.pth\"\n",
    "num_epoch_per_run = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "5ab0b0cd-1b41-460c-b3d5-bfb026b34e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pretrained_net = AgentNet()\n",
    "# pretrained_net.load_state_dict(torch.load(pretrained_weight_path))\n",
    "# torch.save(pretrained_net.state_dict(), weigth_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "7f5db558-2318-4b20-8385-a775144067cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = AgentNet()\n",
    "pretrained_net = AgentNet()\n",
    "pretrained_net.load_state_dict(torch.load(pretrained_weight_path))\n",
    "net.cnn.load_state_dict(pretrained_net.cnn.state_dict())\n",
    "torch.save(net.state_dict(), weight_path)\n",
    "optimizer = optim.AdamW(net.mlp.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "4fea4551-3f68-4965-bf24-adca6abf13f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.AdamW(net.mlp.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e02d0f",
   "metadata": {},
   "source": [
    "EVENT_HORIZON = {\n",
    "    MOVED_LEFT: 1,\n",
    "    MOVED_RIGHT: 1,\n",
    "    MOVED_UP: 1,\n",
    "    MOVED_DOWN: 1,\n",
    "    WAITED: 1,\n",
    "    INVALID_ACTION: 1,\n",
    "    BOMB_DROPPED: 1,\n",
    "    BOMB_EXPLODED: 1,\n",
    "    CRATE_DESTROYED: 5,\n",
    "    COIN_FOUND: 3,\n",
    "    COIN_COLLECTED: 8,\n",
    "    KILLED_OPPONENT: 8,\n",
    "    KILLED_SELF: 4,\n",
    "    GOT_KILLED: 3,\n",
    "    OPPONENT_ELIMINATED: 7,\n",
    "    SURVIVED_ROUND: 5\n",
    "}\n",
    "\n",
    "\n",
    "REWARDS = {\n",
    "    MOVED_LEFT: -0.5,  #-0.2\n",
    "    MOVED_RIGHT: -0.5, #-0.2\n",
    "    MOVED_UP: -0.5,  #-0.2\n",
    "    MOVED_DOWN: -0.5,  #-0.2    \n",
    "    WAITED: 4,\n",
    "    INVALID_ACTION: -2,\n",
    "    BOMB_DROPPED: 0,\n",
    "    BOMB_EXPLODED: 1,\n",
    "    CRATE_DESTROYED: 2,\n",
    "    COIN_FOUND: 0,\n",
    "    COIN_COLLECTED: 6,\n",
    "    KILLED_OPPONENT: 1,\n",
    "    KILLED_SELF: -10,\n",
    "    GOT_KILLED: -1,\n",
    "    OPPONENT_ELIMINATED: 2,\n",
    "    SURVIVED_ROUND: 9\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "77764d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "action_probs = np.zeros((6,500))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "7ee713ae-2c19-4c00-9eb0-daf9d05fd540",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:58<00:00,  1.94s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 298683 actions.\n",
      "298683 actions in the training set:\n",
      "UP: 15.22% (45452)\n",
      "DOWN: 34.32% (102520)\n",
      "LEFT: 16.40% (48982)\n",
      "RIGHT: 26.48% (79098)\n",
      "BOMB: 6.45% (19274)\n",
      "WAIT: 1.12% (3357)\n",
      "[1, 1,   200] loss: 20.545\n",
      "[1, 1,   400] loss: 17.363\n",
      "[1, 1,   600] loss: 15.881\n",
      "[1, 1,   800] loss: 15.734\n",
      "[1, 1,  1000] loss: 14.239\n",
      "[1, 1,  1200] loss: 13.750\n",
      "[1, 1,  1400] loss: 13.503\n",
      "[1, 1,  1600] loss: 13.106\n",
      "[1, 1,  1800] loss: 12.162\n",
      "[1, 1,  2000] loss: 12.178\n",
      "[1, 1,  2200] loss: 11.820\n",
      "[1, 1,  2400] loss: 11.852\n",
      "[1, 1,  2600] loss: 11.281\n",
      "[1, 1,  2800] loss: 11.148\n",
      "[1, 1,  3000] loss: 10.654\n",
      "[1, 1,  3200] loss: 11.071\n",
      "[1, 1,  3400] loss: 10.446\n",
      "[1, 1,  3600] loss: 10.402\n",
      "[1, 1,  3800] loss: 9.904\n",
      "[1, 1,  4000] loss: 9.635\n",
      "[1, 1,  4200] loss: 9.458\n",
      "[1, 1,  4400] loss: 9.511\n",
      "[1, 1,  4600] loss: 9.639\n",
      "[1, 1] loss: 9.649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:58<00:00,  1.94s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 275019 actions.\n",
      "275019 actions in the training set:\n",
      "UP: 14.84% (40818)\n",
      "DOWN: 35.45% (97483)\n",
      "LEFT: 16.15% (44411)\n",
      "RIGHT: 26.31% (72357)\n",
      "BOMB: 6.03% (16597)\n",
      "WAIT: 1.22% (3353)\n",
      "[2, 1,   200] loss: 15.642\n",
      "[2, 1,   400] loss: 12.522\n",
      "[2, 1,   600] loss: 10.814\n",
      "[2, 1,   800] loss: 10.197\n",
      "[2, 1,  1000] loss: 9.779\n",
      "[2, 1,  1200] loss: 8.961\n",
      "[2, 1,  1400] loss: 8.457\n",
      "[2, 1,  1600] loss: 8.409\n",
      "[2, 1,  1800] loss: 8.007\n",
      "[2, 1,  2000] loss: 7.834\n",
      "[2, 1,  2200] loss: 7.641\n",
      "[2, 1,  2400] loss: 7.661\n",
      "[2, 1,  2600] loss: 7.253\n",
      "[2, 1,  2800] loss: 6.938\n",
      "[2, 1,  3000] loss: 6.859\n",
      "[2, 1,  3200] loss: 7.091\n",
      "[2, 1,  3400] loss: 7.851\n",
      "[2, 1,  3600] loss: 6.596\n",
      "[2, 1,  3800] loss: 7.056\n",
      "[2, 1,  4000] loss: 6.786\n",
      "[2, 1,  4200] loss: 6.336\n",
      "[2, 1] loss: 5.841\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [01:02<00:00,  2.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 296943 actions.\n",
      "296943 actions in the training set:\n",
      "UP: 14.74% (43777)\n",
      "DOWN: 34.50% (102442)\n",
      "LEFT: 15.75% (46779)\n",
      "RIGHT: 27.90% (82858)\n",
      "BOMB: 5.79% (17200)\n",
      "WAIT: 1.31% (3887)\n",
      "[3, 1,   200] loss: 13.117\n",
      "[3, 1,   400] loss: 10.529\n",
      "[3, 1,   600] loss: 8.514\n",
      "[3, 1,   800] loss: 7.821\n",
      "[3, 1,  1000] loss: 7.589\n",
      "[3, 1,  1200] loss: 7.152\n",
      "[3, 1,  1400] loss: 6.555\n",
      "[3, 1,  1600] loss: 6.769\n",
      "[3, 1,  1800] loss: 6.426\n",
      "[3, 1,  2000] loss: 6.444\n",
      "[3, 1,  2200] loss: 6.472\n",
      "[3, 1,  2400] loss: 6.159\n",
      "[3, 1,  2600] loss: 5.700\n",
      "[3, 1,  2800] loss: 6.195\n",
      "[3, 1,  3000] loss: 6.146\n",
      "[3, 1,  3200] loss: 6.141\n",
      "[3, 1,  3400] loss: 5.716\n",
      "[3, 1,  3600] loss: 5.535\n",
      "[3, 1,  3800] loss: 5.579\n",
      "[3, 1,  4000] loss: 5.579\n",
      "[3, 1,  4200] loss: 6.154\n",
      "[3, 1,  4400] loss: 5.372\n",
      "[3, 1,  4600] loss: 5.222\n",
      "[3, 1] loss: 6.239\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:53<00:00,  1.80s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 288673 actions.\n",
      "288673 actions in the training set:\n",
      "UP: 14.39% (41553)\n",
      "DOWN: 41.43% (119600)\n",
      "LEFT: 15.19% (43854)\n",
      "RIGHT: 22.47% (64863)\n",
      "BOMB: 5.37% (15504)\n",
      "WAIT: 1.14% (3299)\n",
      "[4, 1,   200] loss: 10.355\n",
      "[4, 1,   400] loss: 8.255\n",
      "[4, 1,   600] loss: 7.762\n",
      "[4, 1,   800] loss: 6.706\n",
      "[4, 1,  1000] loss: 6.530\n",
      "[4, 1,  1200] loss: 6.148\n",
      "[4, 1,  1400] loss: 5.509\n",
      "[4, 1,  1600] loss: 5.585\n",
      "[4, 1,  1800] loss: 5.632\n",
      "[4, 1,  2000] loss: 5.073\n",
      "[4, 1,  2200] loss: 4.864\n",
      "[4, 1,  2400] loss: 5.536\n",
      "[4, 1,  2600] loss: 5.197\n",
      "[4, 1,  2800] loss: 4.650\n",
      "[4, 1,  3000] loss: 5.106\n",
      "[4, 1,  3200] loss: 5.531\n",
      "[4, 1,  3400] loss: 4.926\n",
      "[4, 1,  3600] loss: 4.624\n",
      "[4, 1,  3800] loss: 4.378\n",
      "[4, 1,  4000] loss: 4.987\n",
      "[4, 1,  4200] loss: 4.764\n",
      "[4, 1,  4400] loss: 4.636\n",
      "[4, 1] loss: 4.888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:52<00:00,  1.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 278948 actions.\n",
      "278948 actions in the training set:\n",
      "UP: 13.04% (36378)\n",
      "DOWN: 39.66% (110624)\n",
      "LEFT: 14.77% (41196)\n",
      "RIGHT: 26.79% (74744)\n",
      "BOMB: 4.77% (13313)\n",
      "WAIT: 0.97% (2693)\n",
      "[5, 1,   200] loss: 11.025\n",
      "[5, 1,   400] loss: 8.949\n",
      "[5, 1,   600] loss: 7.630\n",
      "[5, 1,   800] loss: 7.161\n",
      "[5, 1,  1000] loss: 6.631\n",
      "[5, 1,  1200] loss: 6.287\n",
      "[5, 1,  1400] loss: 6.397\n",
      "[5, 1,  1600] loss: 5.681\n",
      "[5, 1,  1800] loss: 6.000\n",
      "[5, 1,  2000] loss: 6.066\n",
      "[5, 1,  2200] loss: 5.989\n",
      "[5, 1,  2400] loss: 5.975\n",
      "[5, 1,  2600] loss: 5.652\n",
      "[5, 1,  2800] loss: 5.766\n",
      "[5, 1,  3000] loss: 5.277\n",
      "[5, 1,  3200] loss: 5.607\n",
      "[5, 1,  3400] loss: 5.522\n",
      "[5, 1,  3600] loss: 5.495\n",
      "[5, 1,  3800] loss: 5.514\n",
      "[5, 1,  4000] loss: 5.363\n",
      "[5, 1,  4200] loss: 5.473\n",
      "[5, 1] loss: 5.809\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:51<00:00,  1.71s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 261623 actions.\n",
      "261623 actions in the training set:\n",
      "UP: 15.45% (40432)\n",
      "DOWN: 39.18% (102493)\n",
      "LEFT: 14.66% (38343)\n",
      "RIGHT: 23.93% (62594)\n",
      "BOMB: 5.39% (14107)\n",
      "WAIT: 1.40% (3654)\n",
      "[6, 1,   200] loss: 10.541\n",
      "[6, 1,   400] loss: 8.960\n",
      "[6, 1,   600] loss: 7.116\n",
      "[6, 1,   800] loss: 6.318\n",
      "[6, 1,  1000] loss: 6.269\n",
      "[6, 1,  1200] loss: 5.886\n",
      "[6, 1,  1400] loss: 6.083\n",
      "[6, 1,  1600] loss: 5.624\n",
      "[6, 1,  1800] loss: 5.623\n",
      "[6, 1,  2000] loss: 5.538\n",
      "[6, 1,  2200] loss: 5.588\n",
      "[6, 1,  2400] loss: 5.382\n",
      "[6, 1,  2600] loss: 5.600\n",
      "[6, 1,  2800] loss: 5.469\n",
      "[6, 1,  3000] loss: 5.517\n",
      "[6, 1,  3200] loss: 5.241\n",
      "[6, 1,  3400] loss: 5.374\n",
      "[6, 1,  3600] loss: 5.240\n",
      "[6, 1,  3800] loss: 5.201\n",
      "[6, 1,  4000] loss: 5.039\n",
      "[6, 1] loss: 5.375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:55<00:00,  1.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 266770 actions.\n",
      "266770 actions in the training set:\n",
      "UP: 15.18% (40502)\n",
      "DOWN: 41.63% (111067)\n",
      "LEFT: 13.93% (37161)\n",
      "RIGHT: 22.58% (60247)\n",
      "BOMB: 5.43% (14481)\n",
      "WAIT: 1.24% (3312)\n",
      "[7, 1,   200] loss: 10.172\n",
      "[7, 1,   400] loss: 8.596\n",
      "[7, 1,   600] loss: 7.097\n",
      "[7, 1,   800] loss: 6.640\n",
      "[7, 1,  1000] loss: 6.194\n",
      "[7, 1,  1200] loss: 6.160\n",
      "[7, 1,  1400] loss: 5.763\n",
      "[7, 1,  1600] loss: 5.387\n",
      "[7, 1,  1800] loss: 5.189\n",
      "[7, 1,  2000] loss: 5.195\n",
      "[7, 1,  2200] loss: 5.018\n",
      "[7, 1,  2400] loss: 5.369\n",
      "[7, 1,  2600] loss: 4.919\n",
      "[7, 1,  2800] loss: 5.100\n",
      "[7, 1,  3000] loss: 5.002\n",
      "[7, 1,  3200] loss: 5.368\n",
      "[7, 1,  3400] loss: 4.856\n",
      "[7, 1,  3600] loss: 5.708\n",
      "[7, 1,  3800] loss: 5.186\n",
      "[7, 1,  4000] loss: 4.962\n",
      "[7, 1] loss: 4.603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:52<00:00,  1.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 272686 actions.\n",
      "272686 actions in the training set:\n",
      "UP: 14.62% (39861)\n",
      "DOWN: 41.77% (113900)\n",
      "LEFT: 11.12% (30333)\n",
      "RIGHT: 26.36% (71867)\n",
      "BOMB: 4.95% (13500)\n",
      "WAIT: 1.18% (3225)\n",
      "[8, 1,   200] loss: 8.618\n",
      "[8, 1,   400] loss: 7.104\n",
      "[8, 1,   600] loss: 6.021\n",
      "[8, 1,   800] loss: 5.576\n",
      "[8, 1,  1000] loss: 5.072\n",
      "[8, 1,  1200] loss: 4.652\n",
      "[8, 1,  1400] loss: 4.711\n",
      "[8, 1,  1600] loss: 4.287\n",
      "[8, 1,  1800] loss: 4.299\n",
      "[8, 1,  2000] loss: 4.500\n",
      "[8, 1,  2200] loss: 4.388\n",
      "[8, 1,  2400] loss: 4.180\n",
      "[8, 1,  2600] loss: 4.070\n",
      "2624\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_28285/2862909088.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     43\u001b[0m             \"\"\"\n\u001b[1;32m     44\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlog_probs\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mrewards\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    485\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m             )\n\u001b[0;32m--> 487\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    488\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m         )\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    201\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for run in range(10):\n",
    "    # os.system(\"rm -rf ../rule_based_agent/data\")\n",
    "    os.system(\"rm -rf ../data\")\n",
    "    #os.system(\"cd ../..; python main.py play --no-gui --agents basic_agent basic_agent basic_agent basic_agent --train 4 --n-rounds 30 --scenario loot-crate\")\n",
    "    os.system(\"cd ../..; python main.py play --no-gui --agents basic_agent basic_agent basic_agent basic_agent  --train 4 --n-rounds 30 --scenario loot-crate\")\n",
    "\n",
    "    # os.system(\"cd ../..; python main.py play --no-gui --agents rule_based_agent rule_based_agent rule_based_agent rule_based_agent --train 4 --n-rounds 10 --scenario classic\")\n",
    "\n",
    "    trainset = BombermanDataset(data_path)\n",
    "    N = len(trainset)\n",
    "    print(f\"{N} actions in the training set:\")\n",
    "    for i in range(6):\n",
    "        n = np.sum([t == i for t in trainset.actions])\n",
    "        print(f\"{ACTION_MAP_INV[i]}: {n/N*100:.2f}% ({n})\")\n",
    "        action_probs[i,run] = n/N\n",
    "    \n",
    "    \n",
    "    # sampler = BatchSampler(WeightedRandomSampler(trainset.weights, len(trainset), replacement=True,), batch_size, False)\n",
    "    # trainloader = torch.utils.data.DataLoader(trainset, batch_sampler=sampler)\n",
    "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    for epoch in range(num_epoch_per_run):\n",
    "        running_loss = 0.0\n",
    "        running = 0\n",
    "        for i, batch in enumerate(trainloader, 0):\n",
    "        # for i, batch in enumerate(sampler, 0):\n",
    "            print(i, end=\"\\r\")\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            (channels, features), actions, rewards = batch\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "    \n",
    "            # forward + backward + optimize\n",
    "            outputs = net(channels, features)\n",
    "            # loss = criterion(outputs, labels)\n",
    "            log_logits = F.log_softmax(outputs, dim=-1)\n",
    "            log_probs = log_logits.gather(1, actions[:,np.newaxis])\n",
    "            \"\"\"\n",
    "            if i == 0:\n",
    "                print(actions, rewards, log_probs)\n",
    "                print(-log_probs * rewards)\n",
    "            \"\"\"\n",
    "            loss = torch.mean(-log_probs * rewards)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "            running += 1\n",
    "            if i % 200 == 199:    # print every 2000 mini-batches\n",
    "                print(f'[{run + 1}, {epoch + 1}, {i + 1:5d}] loss: {running_loss / running:.3f}')\n",
    "                torch.save(net.state_dict(), weight_path)\n",
    "                running_loss = 0.0\n",
    "                running = 0\n",
    "        if running > 0:\n",
    "            print(f'[{run + 1}, {epoch + 1}] loss: {running_loss / running:.3f}')\n",
    "    torch.save(net.state_dict(), weight_path)\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1e729cf5-51d3-499c-a029-dcc14cc8954c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 0. 0. 0.]]\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "a = np.zeros((1,7))\n",
    "print(a)\n",
    "print(a[0])\n",
    "print(a[0,0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2c53db6b-c671-4001-a638-de64bbee8438",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 5 6]\n",
      "[1 2 3 4 5 6]\n"
     ]
    }
   ],
   "source": [
    "a = np.array([1,2,3,4,5,6,7])-1\n",
    "print(a)\n",
    "print(a[1:7])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d258b3d",
   "metadata": {},
   "source": [
    "\n",
    "    extensions = np.zeros(4)\n",
    "    if pos[0]+4 <= 16:             #field, box_map, explosion_map, others_map, coin_map\n",
    "        if field[pos[0]+4, pos[1]] == 1:\n",
    "            extensions[0] = 1\n",
    "        if box_map[pos[0]+4, pos[1]] ==1:\n",
    "            extensions[0] = 2\n",
    "        if explosion_map[pos[0]+4, pos[1]] ==1:\n",
    "            extensions[0] = 3\n",
    "        if others_map[pos[0]+4, pos[1]] == 1:\n",
    "            extensions[0] = 4\n",
    "        if coin_map[pos[0]+4, pos[1]] ==1:\n",
    "            extensions[0] =5\n",
    "\n",
    "    if pos[0]-4 >= 0:             #field, box_map, explosion_map, others_map, coin_map\n",
    "        if field[pos[0]-4, pos[1]] == 1:\n",
    "            extensions[1] = 1\n",
    "        if box_map[pos[0]-4, pos[1]] ==1:\n",
    "            extensions[1] = 2\n",
    "        if explosion_map[pos[0]+4, pos[1]] ==1:\n",
    "            extensions[1] = 3\n",
    "        if others_map[pos[0]-4, pos[1]] == 1:\n",
    "            extensions[1] = 4\n",
    "        if coin_map[pos[0]-4, pos[1]] ==1:\n",
    "            extensions[1] =5\n",
    "\n",
    "    if pos[1]+4 <= 16:             #field, box_map, explosion_map, others_map, coin_map\n",
    "        if field[pos[0], pos[1]+4] == 1:\n",
    "            extensions[2] = 1\n",
    "        if box_map[pos[0], pos[1]+4] ==1:\n",
    "            extensions[2] = 2\n",
    "        if explosion_map[pos[0], pos[1]+4] ==1:\n",
    "            extensions[2] = 3\n",
    "        if others_map[pos[0], pos[1]+4] == 1:\n",
    "            extensions[2] = 4\n",
    "        if coin_map[pos[0], pos[1]+4] ==1:\n",
    "            extensions[2] = 5\n",
    "\n",
    "    if pos[1]-4 >= 0:             #field, box_map, explosion_map, others_map, coin_map\n",
    "        if field[pos[0], pos[1]-4] == 1:\n",
    "            extensions[3] = 1\n",
    "        if box_map[pos[0], pos[1]-4] ==1:\n",
    "            extensions[3] = 2\n",
    "        if explosion_map[pos[0], pos[1]-4] ==1:\n",
    "            extensions[3] = 3\n",
    "        if others_map[pos[0], pos[1]-4] == 1:\n",
    "            extensions[3] = 4\n",
    "        if coin_map[pos[0], pos[1]-4] ==1:\n",
    "            extensions[3] = 5\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
