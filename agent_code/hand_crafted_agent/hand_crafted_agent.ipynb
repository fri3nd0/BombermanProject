{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bbe88005-be9f-46e7-8600-019ed0bc7dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "sys.path.append(r\"../..\")\n",
    "\n",
    "\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from callbacks import state_to_features, ACTION_MAP, ACTION_MAP_INV\n",
    "from networks import AgentNet\n",
    "\n",
    "from events import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7369f91a-b21e-407c-bced-63e441be02a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class BombermanDataset(Dataset):\n",
    "    def __init__(self, states_dir, max_game_step=200, min_reward=1):\n",
    "        self.features = []\n",
    "        self.actions = []\n",
    "        self.cum_rewards = []\n",
    "        self.total_number = 0\n",
    "        for num, states_file in enumerate(os.listdir(states_dir)):\n",
    "            print(f\"{num}\", end=\"\\r\")\n",
    "\n",
    "            if not states_file.endswith('.pickle'):\n",
    "                continue\n",
    "            with open(os.path.join(states_dir, states_file), \"rb\") as f:\n",
    "                data = pickle.load(f)\n",
    "            self.total_number += len(data['game_state'])\n",
    "            last_round = -1\n",
    "            running_horizons = []\n",
    "            running_rewards = []\n",
    "            for i in range(len(data['game_state'])-1,-1,-1):\n",
    "                game_state = data['game_state'][i]               \n",
    "\n",
    "                    \n",
    "                if last_round != game_state['round']:\n",
    "                    last_round = game_state['round']\n",
    "                    running_horizons = []\n",
    "                    running_rewards = []\n",
    "                if game_state['step'] > max_game_step:\n",
    "                    continue\n",
    "                    \n",
    "                # determine if action should be included in training set\n",
    "                \n",
    "                horizons = [EVENT_HORIZON[e] for e in data['events'][i]]\n",
    "                rewards = [REWARDS[e] for e in data['events'][i]]\n",
    "                cr = np.where(data['events'] == \"CRATE_DESTROYED\")         \n",
    "\n",
    "                running_rewards = [r for j,r in enumerate(running_rewards) if running_horizons[j]>1]\n",
    "                running_horizons = [h-1 for h in running_horizons if h > 1]\n",
    "                running_rewards.extend(rewards)\n",
    "                running_horizons.extend(horizons)\n",
    "\n",
    "                self.cum_rewards.append(np.sum(running_rewards))\n",
    "\n",
    "                last_action = None if game_state['step'] == 1 else data['action'][i-1]\n",
    "                \n",
    "                features, act_map = state_to_features(game_state, r=4, last_action=last_action)\n",
    "                action = ACTION_MAP[act_map[data['action'][i]]]\n",
    "                self.features.append({key: torch.tensor(value, dtype=torch.float) for key, value in features.items()})\n",
    "                self.actions.append(action)\n",
    "\n",
    "        self.actions = torch.tensor(self.actions)\n",
    "        self.cum_rewards = torch.tensor(self.cum_rewards, dtype=torch.float)\n",
    "\n",
    "        print(f\"Loaded {len(self.actions)} actions.\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.features[idx], self.actions[idx], self.cum_rewards[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "944b4018-e9a4-45ce-825b-41f22809126e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = f\"../data/\"\n",
    "weight_path = \"models/model_weights_pre.pth\"\n",
    "num_epoch_per_run = 1\n",
    "\n",
    "# optimizer = optim.SGD(net.parameters(), momentum=0.9, lr=0.001)\n",
    "net = AgentNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b090f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.AdamW(net.parameters(), lr=0.001)\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a87534bb-9e02-4b62-8053-194d219d0ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "EVENT_HORIZON = {\n",
    "    MOVED_LEFT: 1,\n",
    "    MOVED_RIGHT: 1,\n",
    "    MOVED_UP: 1,\n",
    "    MOVED_DOWN: 1,\n",
    "    WAITED: 1,\n",
    "    INVALID_ACTION: 1,\n",
    "    BOMB_DROPPED: 1,\n",
    "    BOMB_EXPLODED: 0,\n",
    "    CRATE_DESTROYED: 5,\n",
    "    COIN_FOUND: 0,\n",
    "    COIN_COLLECTED: 5,\n",
    "    KILLED_OPPONENT: 8,\n",
    "    KILLED_SELF: 5,\n",
    "    GOT_KILLED: 5,\n",
    "    OPPONENT_ELIMINATED: 0,\n",
    "    SURVIVED_ROUND: 0,\n",
    "}\n",
    "\n",
    "MOVE_REWARD = 1\n",
    "REWARDS = {\n",
    "    MOVED_LEFT: MOVE_REWARD,\n",
    "    MOVED_RIGHT: MOVE_REWARD,\n",
    "    MOVED_UP: MOVE_REWARD,\n",
    "    MOVED_DOWN: MOVE_REWARD,\n",
    "    WAITED: MOVE_REWARD,\n",
    "    INVALID_ACTION: -1,\n",
    "    BOMB_DROPPED: -2,\n",
    "    BOMB_EXPLODED: 0,\n",
    "    CRATE_DESTROYED: 6,\n",
    "    COIN_FOUND: 0,\n",
    "    COIN_COLLECTED: 10,\n",
    "    KILLED_OPPONENT: 1,\n",
    "    KILLED_SELF: 0,\n",
    "    GOT_KILLED: -10,\n",
    "    OPPONENT_ELIMINATED: 0,\n",
    "    SURVIVED_ROUND: 0,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f25651b-d431-4812-be1b-1419aeccbf0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = []\n",
    "for run in range(20):\n",
    "    # os.system(\"rm -rf ../rule_based_agent/data\")\n",
    "    os.system(\"rm -rf ../data\")\n",
    "    os.system(\"cd ../..; python main.py play --no-gui --agents rule_based_agent rule_based_agent rule_based_agent rule_based_agent --train 4 --n-rounds 10 --scenario loot-crate\")\n",
    "\n",
    "    trainset = BombermanDataset(data_path)\n",
    "    N = len(trainset)\n",
    "    print(f\"{N} actions in the training set:\")\n",
    "    for i in range(6):\n",
    "        n = np.sum(trainset.actions.numpy() == i)\n",
    "        print(f\"{ACTION_MAP_INV[i]}: {n/N*100:.2f}% ({n})\")\n",
    "\n",
    "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    for epoch in range(num_epoch_per_run):\n",
    "        running_loss = 0.0\n",
    "        running = 0\n",
    "        for i, batch in enumerate(trainloader, 0):\n",
    "        # for i, batch in enumerate(sampler, 0):\n",
    "            print(i, end=\"\\r\")\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            features, actions, rewards = batch\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "    \n",
    "            # forward + backward + optimize\n",
    "            outputs = net(features['coin_view'], features['local_view'], features['features'])\n",
    "            # loss = criterion(outputs, labels)\n",
    "            log_logits = F.log_softmax(outputs, dim=-1)\n",
    "            log_probs = log_logits.gather(1, actions[:,np.newaxis])\n",
    "            \n",
    "            loss = torch.mean(-log_probs * rewards)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "            running += 1\n",
    "            if i % 200 == 199:    # print every 2000 mini-batches\n",
    "                print(f'[{run + 1}, {epoch + 1}, {i + 1:5d}] loss: {running_loss / running:.3f}')\n",
    "                torch.save(net.state_dict(), weight_path)\n",
    "                if i == 199:\n",
    "                    losses.append(running_loss / running)\n",
    "                running_loss = 0.0\n",
    "                running = 0\n",
    "\n",
    "        if running > 0:\n",
    "            print(f'[{run + 1}, {epoch + 1}] loss: {running_loss / running:.3f}')\n",
    "            \n",
    "    torch.save(net.state_dict(), weight_path)\n",
    "\n",
    "np.save(\"models/losses_pre.npy\", np.array(losses))\n",
    "print('Finished Training') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b32258df",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_path = \"models/model_weights_fine.pth\"\n",
    "optimizer = optim.AdamW(net.parameters(), lr=0.0001)\n",
    "batch_size = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d7f345c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:04<00:00,  2.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 33887 actions.\n",
      "33887 actions in the training set:\n",
      "UP: 19.24% (6519)\n",
      "DOWN: 25.09% (8501)\n",
      "LEFT: 19.51% (6611)\n",
      "RIGHT: 26.07% (8833)\n",
      "BOMB: 8.36% (2832)\n",
      "WAIT: 1.74% (591)\n",
      "[1, 1] loss: 4.133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:05<00:00,  1.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 35939 actions.\n",
      "35939 actions in the training set:\n",
      "UP: 19.27% (6925)\n",
      "DOWN: 24.95% (8967)\n",
      "LEFT: 19.61% (7047)\n",
      "RIGHT: 25.45% (9148)\n",
      "BOMB: 8.87% (3189)\n",
      "WAIT: 1.84% (663)\n",
      "[2, 1] loss: 4.144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:05<00:00,  1.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 34620 actions.\n",
      "34620 actions in the training set:\n",
      "UP: 19.38% (6710)\n",
      "DOWN: 25.17% (8714)\n",
      "LEFT: 19.99% (6922)\n",
      "RIGHT: 25.01% (8660)\n",
      "BOMB: 8.56% (2965)\n",
      "WAIT: 1.87% (649)\n",
      "[3, 1] loss: 4.254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:06<00:00,  1.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 35016 actions.\n",
      "35016 actions in the training set:\n",
      "UP: 19.99% (7001)\n",
      "DOWN: 25.48% (8923)\n",
      "LEFT: 19.36% (6780)\n",
      "RIGHT: 24.64% (8627)\n",
      "BOMB: 8.72% (3053)\n",
      "WAIT: 1.80% (632)\n",
      "[4, 1] loss: 4.149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:05<00:00,  1.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 36326 actions.\n",
      "36326 actions in the training set:\n",
      "UP: 19.10% (6940)\n",
      "DOWN: 24.49% (8896)\n",
      "LEFT: 19.96% (7250)\n",
      "RIGHT: 26.06% (9467)\n",
      "BOMB: 8.78% (3191)\n",
      "WAIT: 1.60% (582)\n",
      "[5, 1] loss: 3.778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:05<00:00,  1.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 34910 actions.\n",
      "34910 actions in the training set:\n",
      "UP: 19.18% (6696)\n",
      "DOWN: 25.75% (8989)\n",
      "LEFT: 19.57% (6833)\n",
      "RIGHT: 25.29% (8829)\n",
      "BOMB: 8.75% (3054)\n",
      "WAIT: 1.46% (509)\n",
      "[6, 1] loss: 4.124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:05<00:00,  1.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 34690 actions.\n",
      "34690 actions in the training set:\n",
      "UP: 19.31% (6697)\n",
      "DOWN: 25.58% (8874)\n",
      "LEFT: 19.61% (6802)\n",
      "RIGHT: 24.94% (8653)\n",
      "BOMB: 8.64% (2996)\n",
      "WAIT: 1.93% (668)\n",
      "[7, 1] loss: 4.072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:05<00:00,  1.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 35455 actions.\n",
      "35455 actions in the training set:\n",
      "UP: 19.06% (6759)\n",
      "DOWN: 24.96% (8851)\n",
      "LEFT: 19.58% (6943)\n",
      "RIGHT: 25.70% (9111)\n",
      "BOMB: 8.73% (3095)\n",
      "WAIT: 1.96% (696)\n",
      "[8, 1] loss: 4.057\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:05<00:00,  1.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 34956 actions.\n",
      "34956 actions in the training set:\n",
      "UP: 19.98% (6983)\n",
      "DOWN: 26.05% (9106)\n",
      "LEFT: 19.42% (6787)\n",
      "RIGHT: 24.33% (8506)\n",
      "BOMB: 8.65% (3023)\n",
      "WAIT: 1.58% (551)\n",
      "[9, 1] loss: 4.148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:06<00:00,  1.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 36593 actions.\n",
      "36593 actions in the training set:\n",
      "UP: 20.54% (7516)\n",
      "DOWN: 25.76% (9426)\n",
      "LEFT: 18.78% (6873)\n",
      "RIGHT: 24.66% (9024)\n",
      "BOMB: 8.63% (3158)\n",
      "WAIT: 1.63% (596)\n",
      "[10, 1] loss: 3.892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:05<00:00,  1.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 34257 actions.\n",
      "34257 actions in the training set:\n",
      "UP: 19.76% (6768)\n",
      "DOWN: 25.17% (8623)\n",
      "LEFT: 19.53% (6690)\n",
      "RIGHT: 25.15% (8617)\n",
      "BOMB: 8.56% (2933)\n",
      "WAIT: 1.83% (626)\n",
      "[11, 1] loss: 4.009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:06<00:00,  1.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 36185 actions.\n",
      "36185 actions in the training set:\n",
      "UP: 19.13% (6922)\n",
      "DOWN: 25.39% (9188)\n",
      "LEFT: 20.11% (7278)\n",
      "RIGHT: 25.41% (9196)\n",
      "BOMB: 8.41% (3044)\n",
      "WAIT: 1.54% (557)\n",
      "[12, 1] loss: 3.980\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:05<00:00,  1.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 32361 actions.\n",
      "32361 actions in the training set:\n",
      "UP: 18.93% (6126)\n",
      "DOWN: 25.28% (8180)\n",
      "LEFT: 19.78% (6401)\n",
      "RIGHT: 25.68% (8311)\n",
      "BOMB: 8.58% (2775)\n",
      "WAIT: 1.76% (568)\n",
      "[13, 1] loss: 3.929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:06<00:00,  1.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 37711 actions.\n",
      "37711 actions in the training set:\n",
      "UP: 19.39% (7312)\n",
      "DOWN: 24.31% (9166)\n",
      "LEFT: 20.33% (7666)\n",
      "RIGHT: 26.05% (9823)\n",
      "BOMB: 8.29% (3128)\n",
      "WAIT: 1.63% (616)\n",
      "[14, 1] loss: 3.888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:05<00:00,  1.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 34481 actions.\n",
      "34481 actions in the training set:\n",
      "UP: 19.40% (6688)\n",
      "DOWN: 25.46% (8778)\n",
      "LEFT: 19.27% (6646)\n",
      "RIGHT: 25.59% (8822)\n",
      "BOMB: 8.40% (2896)\n",
      "WAIT: 1.89% (651)\n",
      "[15, 1] loss: 4.096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:05<00:00,  1.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 35046 actions.\n",
      "35046 actions in the training set:\n",
      "UP: 18.36% (6435)\n",
      "DOWN: 23.40% (8201)\n",
      "LEFT: 21.21% (7434)\n",
      "RIGHT: 27.18% (9524)\n",
      "BOMB: 8.55% (2996)\n",
      "WAIT: 1.30% (456)\n",
      "[16, 1] loss: 3.940\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:05<00:00,  1.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 35091 actions.\n",
      "35091 actions in the training set:\n",
      "UP: 19.88% (6976)\n",
      "DOWN: 25.25% (8862)\n",
      "LEFT: 19.31% (6775)\n",
      "RIGHT: 24.78% (8697)\n",
      "BOMB: 8.75% (3069)\n",
      "WAIT: 2.03% (712)\n",
      "[17, 1] loss: 3.867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:05<00:00,  1.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 34784 actions.\n",
      "34784 actions in the training set:\n",
      "UP: 19.59% (6813)\n",
      "DOWN: 25.01% (8699)\n",
      "LEFT: 18.95% (6591)\n",
      "RIGHT: 25.89% (9006)\n",
      "BOMB: 8.74% (3040)\n",
      "WAIT: 1.83% (635)\n",
      "[18, 1] loss: 3.959\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:06<00:00,  1.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 36455 actions.\n",
      "36455 actions in the training set:\n",
      "UP: 20.26% (7384)\n",
      "DOWN: 24.32% (8867)\n",
      "LEFT: 19.55% (7127)\n",
      "RIGHT: 25.56% (9319)\n",
      "BOMB: 8.93% (3255)\n",
      "WAIT: 1.38% (503)\n",
      "[19, 1] loss: 3.950\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:05<00:00,  1.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 35063 actions.\n",
      "35063 actions in the training set:\n",
      "UP: 20.03% (7024)\n",
      "DOWN: 25.28% (8863)\n",
      "LEFT: 19.49% (6835)\n",
      "RIGHT: 24.32% (8528)\n",
      "BOMB: 8.91% (3125)\n",
      "WAIT: 1.96% (688)\n",
      "[20, 1] loss: 3.756\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "for run in range(20):\n",
    "    # os.system(\"rm -rf ../rule_based_agent/data\")\n",
    "    os.system(\"rm -rf ../data\")\n",
    "    os.system(\"cd ../..; python main.py play --no-gui --agents rule_based_agent rule_based_agent rule_based_agent rule_based_agent --train 4 --n-rounds 10 --scenario loot-crate\")\n",
    "\n",
    "    trainset = BombermanDataset(data_path)\n",
    "    N = len(trainset)\n",
    "    print(f\"{N} actions in the training set:\")\n",
    "    for i in range(6):\n",
    "        n = np.sum(trainset.actions.numpy() == i)\n",
    "        print(f\"{ACTION_MAP_INV[i]}: {n/N*100:.2f}% ({n})\")\n",
    "    # sampler = BatchSampler(WeightedRandomSampler(trainset.weights, len(trainset), replacement=True,), batch_size, False)\n",
    "    # trainloader = torch.utils.data.DataLoader(trainset, batch_sampler=sampler)\n",
    "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    for epoch in range(num_epoch_per_run):\n",
    "        running_loss = 0.0\n",
    "        running = 0\n",
    "        for i, batch in enumerate(trainloader, 0):\n",
    "        # for i, batch in enumerate(sampler, 0):\n",
    "            print(i, end=\"\\r\")\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            features, actions, rewards = batch\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "    \n",
    "            # forward + backward + optimize\n",
    "            outputs = net(features['coin_view'], features['local_view'], features['features'])\n",
    "            # loss = criterion(outputs, labels)\n",
    "            log_logits = F.log_softmax(outputs, dim=-1)\n",
    "            log_probs = log_logits.gather(1, actions[:,np.newaxis])\n",
    "            \n",
    "            loss = torch.mean(-log_probs * rewards)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "            running += 1\n",
    "            if i % 200 == 199:    # print every 2000 mini-batches\n",
    "                print(f'[{run + 1}, {epoch + 1}, {i + 1:5d}] loss: {running_loss / running:.3f}')\n",
    "                torch.save(net.state_dict(), weight_path)\n",
    "                if i == 199:\n",
    "                    losses.append(running_loss / running)\n",
    "                running_loss = 0.0\n",
    "                running = 0\n",
    "        \n",
    "        if i < 199:\n",
    "            losses.append(running_loss / running)\n",
    "        if running > 0:\n",
    "            print(f'[{run + 1}, {epoch + 1}] loss: {running_loss / running:.3f}')\n",
    "            \n",
    "    torch.save(net.state_dict(), weight_path)\n",
    "\n",
    "np.save(\"models/losses_fine.npy\", np.array(losses))\n",
    "print('Finished Training') "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mle",
   "language": "python",
   "name": "mle"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
